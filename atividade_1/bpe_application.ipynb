{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Byte-Pair Encoding\n",
    "\n",
    "This notebook shows how the class BPETokenization is used. We're going to go with an example step-by-step and let a notebook cell prepared to preprocess all the corpus elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure visibility for the class file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "LIB_PATH = os.path.join(os.getcwd(), '../')\n",
    "sys.path.append(LIB_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-by-step example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atividade_1.bpe_tokenization import BPETokenization\n",
    "\n",
    "bpe = BPETokenization(vocab_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BPE algorithm relies on 3 major steps:\n",
    "1. Convert a text to a byte representation, which we encode to integer IDs for convinience;\n",
    "2. Count the number of adjacent pairs of bytes;\n",
    "3. Given the most frequent byte pair, we merge this pair into a new token ID\n",
    "\n",
    "We repeat this process until the vocabulary size reaches the value specified at the `vocab_size` class parameter. Jumping to code, we have the implementation as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: VASCO VASCO VASCO DA GAMA\n",
      "Byte IDs: [86, 65, 83, 67, 79, 32, 86, 65, 83, 67, 79, 32, 86, 65, 83, 67, 79, 32, 68, 65, 32, 71, 65, 77, 65]\n"
     ]
    }
   ],
   "source": [
    "# The first step is to convert from a string to a list of byte ids\n",
    "text = \"VASCO VASCO VASCO DA GAMA\"\n",
    "print(f\"Original Text: {text}\")\n",
    "byte_ids = bpe.text_to_byte_ids(text)\n",
    "print(f\"Byte IDs: {byte_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair Counts: {(86, 65): 3, (65, 83): 3, (83, 67): 3, (67, 79): 3, (79, 32): 3, (32, 86): 2, (32, 68): 1, (68, 65): 1, (65, 32): 1, (32, 71): 1, (71, 65): 1, (65, 77): 1, (77, 65): 1}\n"
     ]
    }
   ],
   "source": [
    "# Then we count the byte adjacent pairs\n",
    "pair_counts = bpe.get_pair_counts(byte_ids)\n",
    "print(f\"Pair Counts: {pair_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent pair: (86, 65)\n"
     ]
    }
   ],
   "source": [
    "# Next, we find the most frequent pair\n",
    "most_freq = bpe.find_most_frequent_pair(pair_counts)\n",
    "print(f\"Most frequent pair: {most_freq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs after the first merge: [87, 83, 67, 79, 32, 87, 83, 67, 79, 32, 87, 83, 67, 79, 32, 68, 65, 32, 71, 65, 77, 65]\n"
     ]
    }
   ],
   "source": [
    "# Lastly, we merge this frequent pair into a new token id, and\n",
    "token_ids = bpe.merge_pair(byte_ids, most_freq, max(byte_ids)+1)\n",
    "print(f\"Token IDs after the first merge: {token_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on the corpus provided\n",
    "\n",
    "I uploaded the `corpus.zip` file to my personal Google Drive, so I can easily retrieve it using the `gdown` lib, and unzip it using `zipfile`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1LtxrgoRfNivPry38pb28hiKDYDCXRSPs\n",
      "From (redirected): https://drive.google.com/uc?id=1LtxrgoRfNivPry38pb28hiKDYDCXRSPs&confirm=t&uuid=c00b2734-2726-44fe-a803-b5b4f944b5f3\n",
      "To: /home/user/unb/unb_mestrado/2_semestre/topicos_nlp/nlp/atividade_1/corpus.zip\n",
      "100%|██████████| 31.7M/31.7M [00:04<00:00, 6.80MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'corpus.zip'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "\n",
    "file_id = '1LtxrgoRfNivPry38pb28hiKDYDCXRSPs'  \n",
    "\n",
    "download_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "\n",
    "output = 'corpus.zip'\n",
    "\n",
    "gdown.download(download_url, output, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile(\"corpus.zip\", \"r\") as f:\n",
    "    f.extractall(\"corpus/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To process all elements in the corpus, just execute the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def corpus_generator(corpus_path: str):\n",
    "    for file in os.listdir(corpus_path):\n",
    "        with open(f\"{corpus_path}/{file}\", \"r\") as f:\n",
    "            json_file = json.load(f)\n",
    "            yield json_file[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:03, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more pairs to merge. Stopping training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bpe = BPETokenization(vocab_size=20000)\n",
    "bpe.train(corpus_generator(\"corpus\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4183"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bpe.reverse_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4183"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bpe.reverse_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That transformations are encapsulated at the `encode` method, and have a `decode` method to bring things to human readable format as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair (97, 32) already in vocabulary. Stopping encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 79,\n",
       " 32,\n",
       " 114,\n",
       " 97,\n",
       " 116,\n",
       " 111,\n",
       " 32,\n",
       " 114,\n",
       " 111,\n",
       " 101,\n",
       " 117,\n",
       " 32,\n",
       " 97,\n",
       " 32,\n",
       " 114,\n",
       " 111,\n",
       " 117,\n",
       " 112,\n",
       " 97,\n",
       " 32,\n",
       " 100,\n",
       " 111,\n",
       " 32,\n",
       " 114,\n",
       " 101,\n",
       " 105,\n",
       " 32,\n",
       " 100,\n",
       " 101,\n",
       " 32,\n",
       " 82,\n",
       " 111,\n",
       " 109,\n",
       " 97,\n",
       " 44,\n",
       " 32,\n",
       " 101,\n",
       " 110,\n",
       " 113,\n",
       " 117,\n",
       " 97,\n",
       " 110,\n",
       " 116,\n",
       " 111,\n",
       " 32,\n",
       " 97,\n",
       " 32,\n",
       " 103,\n",
       " 114,\n",
       " 97,\n",
       " 110,\n",
       " 100,\n",
       " 101,\n",
       " 32,\n",
       " 101,\n",
       " 32,\n",
       " 118,\n",
       " 101,\n",
       " 103,\n",
       " 101,\n",
       " 116,\n",
       " 97,\n",
       " 114,\n",
       " 105,\n",
       " 97,\n",
       " 110,\n",
       " 97,\n",
       " 32,\n",
       " 102,\n",
       " 108,\n",
       " 111,\n",
       " 114,\n",
       " 32,\n",
       " 100,\n",
       " 101,\n",
       " 32,\n",
       " 108,\n",
       " 105,\n",
       " 115,\n",
       " 32,\n",
       " 100,\n",
       " 97,\n",
       " 110,\n",
       " 195,\n",
       " 167,\n",
       " 97,\n",
       " 118,\n",
       " 97,\n",
       " 32,\n",
       " 110,\n",
       " 97,\n",
       " 115,\n",
       " 32,\n",
       " 110,\n",
       " 117,\n",
       " 118,\n",
       " 101,\n",
       " 110,\n",
       " 115,\n",
       " 32,\n",
       " 100,\n",
       " 101,\n",
       " 32,\n",
       " 83,\n",
       " 104,\n",
       " 105,\n",
       " 107,\n",
       " 97,\n",
       " 109,\n",
       " 97,\n",
       " 114,\n",
       " 117,\n",
       " 46,\n",
       " 1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eae = bpe.encode(text=\"O rato roeu a roupa do rei de Roma, enquanto a grande e vegetariana flor de lis dançava nas nuvens de Shikamaru.\")\n",
    "eae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O rato roeu a roupa do rei de Roma, enquanto a grande e vegetariana flor de lis dançava nas nuvens de Shikamaru.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe.decode(ids=eae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
