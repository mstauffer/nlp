{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final metrics\n",
    "\n",
    "Here we have the best configurations for the three selected models, let's see how the behave of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv145_12239.txt</td>\n",
       "      <td>it was once said that in order to truly enjoy ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv745_14009.txt</td>\n",
       "      <td>conventional wisdom among collectibles retaile...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cv376_20883.txt</td>\n",
       "      <td>robin williams has the rarest of gifts : the a...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cv109_22599.txt</td>\n",
       "      <td>nearly every film tim burton has directed has ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cv494_18689.txt</td>\n",
       "      <td>you know , i never really wondered what the ta...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>cv964_6021.txt</td>\n",
       "      <td>you've got to think twice before you go see a ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>cv989_15824.txt</td>\n",
       "      <td>lisa cholodenko's \" high art , \" is an intelli...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>cv355_16413.txt</td>\n",
       "      <td>to paraphrase a song title from an earlier dis...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>cv463_10343.txt</td>\n",
       "      <td>one fun activity for parents during the holida...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>cv265_10814.txt</td>\n",
       "      <td>one way of telling if a film is good or not is...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            file_name                                               text class\n",
       "0     cv145_12239.txt  it was once said that in order to truly enjoy ...   neg\n",
       "1     cv745_14009.txt  conventional wisdom among collectibles retaile...   neg\n",
       "2     cv376_20883.txt  robin williams has the rarest of gifts : the a...   neg\n",
       "3     cv109_22599.txt  nearly every film tim burton has directed has ...   neg\n",
       "4     cv494_18689.txt  you know , i never really wondered what the ta...   neg\n",
       "...               ...                                                ...   ...\n",
       "1995   cv964_6021.txt  you've got to think twice before you go see a ...   pos\n",
       "1996  cv989_15824.txt  lisa cholodenko's \" high art , \" is an intelli...   pos\n",
       "1997  cv355_16413.txt  to paraphrase a song title from an earlier dis...   pos\n",
       "1998  cv463_10343.txt  one fun activity for parents during the holida...   pos\n",
       "1999  cv265_10814.txt  one way of telling if a film is good or not is...   pos\n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../text_databases/review_polarity.csv\")\n",
    "data.fillna('', inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Same split used on hyperparameters search\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['class'],\n",
    "                                                    test_size=0.2, random_state=14,\n",
    "                                                    stratify=data['class'])\n",
    "\n",
    "split_data = [X_train, X_test, y_train, y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__alpha</th>\n",
       "      <th>param_vectorizer__ngram_range</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.028799</td>\n",
       "      <td>0.127444</td>\n",
       "      <td>0.775253</td>\n",
       "      <td>0.029083</td>\n",
       "      <td>0.20</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>{'classifier__alpha': 0.2, 'vectorizer__ngram_...</td>\n",
       "      <td>0.815625</td>\n",
       "      <td>0.821875</td>\n",
       "      <td>0.831250</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.832500</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.745336</td>\n",
       "      <td>0.235539</td>\n",
       "      <td>0.680357</td>\n",
       "      <td>0.016727</td>\n",
       "      <td>0.10</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>{'classifier__alpha': 0.1, 'vectorizer__ngram_...</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.831250</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.837500</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.282275</td>\n",
       "      <td>0.132089</td>\n",
       "      <td>0.799413</td>\n",
       "      <td>0.032767</td>\n",
       "      <td>0.50</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>{'classifier__alpha': 0.5, 'vectorizer__ngram_...</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.837500</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.828750</td>\n",
       "      <td>0.010155</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.462357</td>\n",
       "      <td>0.234974</td>\n",
       "      <td>0.495211</td>\n",
       "      <td>0.015007</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__alpha': 0.75, 'vectorizer__ngram...</td>\n",
       "      <td>0.809375</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.815625</td>\n",
       "      <td>0.834375</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.824375</td>\n",
       "      <td>0.012717</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.403174</td>\n",
       "      <td>0.117572</td>\n",
       "      <td>0.435836</td>\n",
       "      <td>0.050699</td>\n",
       "      <td>0.20</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__alpha': 0.2, 'vectorizer__ngram_...</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.809375</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.834375</td>\n",
       "      <td>0.834375</td>\n",
       "      <td>0.820625</td>\n",
       "      <td>0.011957</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.114014</td>\n",
       "      <td>0.049611</td>\n",
       "      <td>0.248444</td>\n",
       "      <td>0.016274</td>\n",
       "      <td>2.00</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'classifier__alpha': 2, 'vectorizer__ngram_ra...</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.831250</td>\n",
       "      <td>0.815625</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.012748</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.515495</td>\n",
       "      <td>0.227925</td>\n",
       "      <td>0.471889</td>\n",
       "      <td>0.036362</td>\n",
       "      <td>0.50</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__alpha': 0.5, 'vectorizer__ngram_...</td>\n",
       "      <td>0.809375</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.815625</td>\n",
       "      <td>0.831250</td>\n",
       "      <td>0.834375</td>\n",
       "      <td>0.818125</td>\n",
       "      <td>0.013020</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8.837058</td>\n",
       "      <td>0.141615</td>\n",
       "      <td>0.942796</td>\n",
       "      <td>0.047200</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>{'classifier__alpha': 0.75, 'vectorizer__ngram...</td>\n",
       "      <td>0.803125</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.815625</td>\n",
       "      <td>0.834375</td>\n",
       "      <td>0.837500</td>\n",
       "      <td>0.816875</td>\n",
       "      <td>0.017071</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.262246</td>\n",
       "      <td>0.212098</td>\n",
       "      <td>0.591803</td>\n",
       "      <td>0.032677</td>\n",
       "      <td>1.00</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__alpha': 1, 'vectorizer__ngram_ra...</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.803125</td>\n",
       "      <td>0.809375</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.816250</td>\n",
       "      <td>0.010155</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.143246</td>\n",
       "      <td>0.075942</td>\n",
       "      <td>0.253999</td>\n",
       "      <td>0.018668</td>\n",
       "      <td>1.50</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'classifier__alpha': 1.5, 'vectorizer__ngram_...</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.815625</td>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.012087</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.378607</td>\n",
       "      <td>0.087086</td>\n",
       "      <td>0.451558</td>\n",
       "      <td>0.033801</td>\n",
       "      <td>0.10</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__alpha': 0.1, 'vectorizer__ngram_...</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.803125</td>\n",
       "      <td>0.809375</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.008149</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9.598509</td>\n",
       "      <td>0.115126</td>\n",
       "      <td>0.926971</td>\n",
       "      <td>0.059012</td>\n",
       "      <td>1.00</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>{'classifier__alpha': 1, 'vectorizer__ngram_ra...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.831250</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.016298</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.015672</td>\n",
       "      <td>0.164793</td>\n",
       "      <td>0.235429</td>\n",
       "      <td>0.032777</td>\n",
       "      <td>1.00</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'classifier__alpha': 1, 'vectorizer__ngram_ra...</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.803125</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.811250</td>\n",
       "      <td>0.011957</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.845971</td>\n",
       "      <td>0.049532</td>\n",
       "      <td>0.181300</td>\n",
       "      <td>0.009398</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'classifier__alpha': 0.75, 'vectorizer__ngram...</td>\n",
       "      <td>0.790625</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.815625</td>\n",
       "      <td>0.809375</td>\n",
       "      <td>0.808750</td>\n",
       "      <td>0.012870</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.818410</td>\n",
       "      <td>0.031180</td>\n",
       "      <td>0.175776</td>\n",
       "      <td>0.018987</td>\n",
       "      <td>0.50</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'classifier__alpha': 0.5, 'vectorizer__ngram_...</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.803125</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.809375</td>\n",
       "      <td>0.807500</td>\n",
       "      <td>0.015130</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.000683</td>\n",
       "      <td>0.140424</td>\n",
       "      <td>0.578850</td>\n",
       "      <td>0.039114</td>\n",
       "      <td>1.50</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__alpha': 1.5, 'vectorizer__ngram_...</td>\n",
       "      <td>0.809375</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.806875</td>\n",
       "      <td>0.011250</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.115123</td>\n",
       "      <td>0.038887</td>\n",
       "      <td>0.244561</td>\n",
       "      <td>0.017327</td>\n",
       "      <td>5.00</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'classifier__alpha': 5, 'vectorizer__ngram_ra...</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.784375</td>\n",
       "      <td>0.815625</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.801875</td>\n",
       "      <td>0.011285</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.816043</td>\n",
       "      <td>0.025339</td>\n",
       "      <td>0.182156</td>\n",
       "      <td>0.009649</td>\n",
       "      <td>0.20</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'classifier__alpha': 0.2, 'vectorizer__ngram_...</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.803125</td>\n",
       "      <td>0.801250</td>\n",
       "      <td>0.014059</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.018898</td>\n",
       "      <td>0.173687</td>\n",
       "      <td>0.566377</td>\n",
       "      <td>0.046200</td>\n",
       "      <td>2.00</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__alpha': 2, 'vectorizer__ngram_ra...</td>\n",
       "      <td>0.803125</td>\n",
       "      <td>0.768750</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.815625</td>\n",
       "      <td>0.801250</td>\n",
       "      <td>0.016840</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.787387</td>\n",
       "      <td>0.003364</td>\n",
       "      <td>0.180439</td>\n",
       "      <td>0.016963</td>\n",
       "      <td>0.10</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'classifier__alpha': 0.1, 'vectorizer__ngram_...</td>\n",
       "      <td>0.778125</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.778125</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.784375</td>\n",
       "      <td>0.793125</td>\n",
       "      <td>0.016465</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.380031</td>\n",
       "      <td>0.181801</td>\n",
       "      <td>0.944407</td>\n",
       "      <td>0.029844</td>\n",
       "      <td>1.50</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>{'classifier__alpha': 1.5, 'vectorizer__ngram_...</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.759375</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.809375</td>\n",
       "      <td>0.803125</td>\n",
       "      <td>0.792500</td>\n",
       "      <td>0.017410</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9.362883</td>\n",
       "      <td>0.169090</td>\n",
       "      <td>0.925947</td>\n",
       "      <td>0.054385</td>\n",
       "      <td>2.00</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>{'classifier__alpha': 2, 'vectorizer__ngram_ra...</td>\n",
       "      <td>0.784375</td>\n",
       "      <td>0.740625</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.784375</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.771875</td>\n",
       "      <td>0.016178</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.873109</td>\n",
       "      <td>0.339915</td>\n",
       "      <td>0.558928</td>\n",
       "      <td>0.044567</td>\n",
       "      <td>5.00</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__alpha': 5, 'vectorizer__ngram_ra...</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.628125</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700625</td>\n",
       "      <td>0.038345</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7.704472</td>\n",
       "      <td>0.584110</td>\n",
       "      <td>0.482079</td>\n",
       "      <td>0.052407</td>\n",
       "      <td>5.00</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>{'classifier__alpha': 5, 'vectorizer__ngram_ra...</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.584375</td>\n",
       "      <td>0.696875</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.681250</td>\n",
       "      <td>0.670625</td>\n",
       "      <td>0.043777</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "5        8.028799      0.127444         0.775253        0.029083   \n",
       "2        7.745336      0.235539         0.680357        0.016727   \n",
       "8        8.282275      0.132089         0.799413        0.032767   \n",
       "10       3.462357      0.234974         0.495211        0.015007   \n",
       "4        3.403174      0.117572         0.435836        0.050699   \n",
       "18       1.114014      0.049611         0.248444        0.016274   \n",
       "7        3.515495      0.227925         0.471889        0.036362   \n",
       "11       8.837058      0.141615         0.942796        0.047200   \n",
       "13       4.262246      0.212098         0.591803        0.032677   \n",
       "15       1.143246      0.075942         0.253999        0.018668   \n",
       "1        3.378607      0.087086         0.451558        0.033801   \n",
       "14       9.598509      0.115126         0.926971        0.059012   \n",
       "12       1.015672      0.164793         0.235429        0.032777   \n",
       "9        0.845971      0.049532         0.181300        0.009398   \n",
       "6        0.818410      0.031180         0.175776        0.018987   \n",
       "16       4.000683      0.140424         0.578850        0.039114   \n",
       "21       1.115123      0.038887         0.244561        0.017327   \n",
       "3        0.816043      0.025339         0.182156        0.009649   \n",
       "19       4.018898      0.173687         0.566377        0.046200   \n",
       "0        0.787387      0.003364         0.180439        0.016963   \n",
       "17       9.380031      0.181801         0.944407        0.029844   \n",
       "20       9.362883      0.169090         0.925947        0.054385   \n",
       "22       3.873109      0.339915         0.558928        0.044567   \n",
       "23       7.704472      0.584110         0.482079        0.052407   \n",
       "\n",
       "    param_classifier__alpha param_vectorizer__ngram_range  \\\n",
       "5                      0.20                        (1, 3)   \n",
       "2                      0.10                        (1, 3)   \n",
       "8                      0.50                        (1, 3)   \n",
       "10                     0.75                        (1, 2)   \n",
       "4                      0.20                        (1, 2)   \n",
       "18                     2.00                        (1, 1)   \n",
       "7                      0.50                        (1, 2)   \n",
       "11                     0.75                        (1, 3)   \n",
       "13                     1.00                        (1, 2)   \n",
       "15                     1.50                        (1, 1)   \n",
       "1                      0.10                        (1, 2)   \n",
       "14                     1.00                        (1, 3)   \n",
       "12                     1.00                        (1, 1)   \n",
       "9                      0.75                        (1, 1)   \n",
       "6                      0.50                        (1, 1)   \n",
       "16                     1.50                        (1, 2)   \n",
       "21                     5.00                        (1, 1)   \n",
       "3                      0.20                        (1, 1)   \n",
       "19                     2.00                        (1, 2)   \n",
       "0                      0.10                        (1, 1)   \n",
       "17                     1.50                        (1, 3)   \n",
       "20                     2.00                        (1, 3)   \n",
       "22                     5.00                        (1, 2)   \n",
       "23                     5.00                        (1, 3)   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "5   {'classifier__alpha': 0.2, 'vectorizer__ngram_...           0.815625   \n",
       "2   {'classifier__alpha': 0.1, 'vectorizer__ngram_...           0.812500   \n",
       "8   {'classifier__alpha': 0.5, 'vectorizer__ngram_...           0.818750   \n",
       "10  {'classifier__alpha': 0.75, 'vectorizer__ngram...           0.809375   \n",
       "4   {'classifier__alpha': 0.2, 'vectorizer__ngram_...           0.806250   \n",
       "18  {'classifier__alpha': 2, 'vectorizer__ngram_ra...           0.796875   \n",
       "7   {'classifier__alpha': 0.5, 'vectorizer__ngram_...           0.809375   \n",
       "11  {'classifier__alpha': 0.75, 'vectorizer__ngram...           0.803125   \n",
       "13  {'classifier__alpha': 1, 'vectorizer__ngram_ra...           0.812500   \n",
       "15  {'classifier__alpha': 1.5, 'vectorizer__ngram_...           0.793750   \n",
       "1   {'classifier__alpha': 0.1, 'vectorizer__ngram_...           0.806250   \n",
       "14  {'classifier__alpha': 1, 'vectorizer__ngram_ra...           0.800000   \n",
       "12  {'classifier__alpha': 1, 'vectorizer__ngram_ra...           0.793750   \n",
       "9   {'classifier__alpha': 0.75, 'vectorizer__ngram...           0.790625   \n",
       "6   {'classifier__alpha': 0.5, 'vectorizer__ngram_...           0.781250   \n",
       "16  {'classifier__alpha': 1.5, 'vectorizer__ngram_...           0.809375   \n",
       "21  {'classifier__alpha': 5, 'vectorizer__ngram_ra...           0.796875   \n",
       "3   {'classifier__alpha': 0.2, 'vectorizer__ngram_...           0.781250   \n",
       "19  {'classifier__alpha': 2, 'vectorizer__ngram_ra...           0.803125   \n",
       "0   {'classifier__alpha': 0.1, 'vectorizer__ngram_...           0.778125   \n",
       "17  {'classifier__alpha': 1.5, 'vectorizer__ngram_...           0.796875   \n",
       "20  {'classifier__alpha': 2, 'vectorizer__ngram_ra...           0.784375   \n",
       "22  {'classifier__alpha': 5, 'vectorizer__ngram_ra...           0.737500   \n",
       "23  {'classifier__alpha': 5, 'vectorizer__ngram_ra...           0.703125   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "5            0.821875           0.831250           0.850000   \n",
       "2            0.825000           0.831250           0.843750   \n",
       "8            0.818750           0.825000           0.837500   \n",
       "10           0.818750           0.815625           0.834375   \n",
       "4            0.809375           0.818750           0.834375   \n",
       "18           0.831250           0.815625           0.828125   \n",
       "7            0.800000           0.815625           0.831250   \n",
       "11           0.793750           0.815625           0.834375   \n",
       "13           0.803125           0.809375           0.828125   \n",
       "15           0.828125           0.812500           0.825000   \n",
       "1            0.803125           0.809375           0.825000   \n",
       "14           0.787500           0.818750           0.831250   \n",
       "12           0.828125           0.803125           0.818750   \n",
       "9            0.828125           0.800000           0.815625   \n",
       "6            0.825000           0.803125           0.818750   \n",
       "16           0.793750           0.793750           0.818750   \n",
       "21           0.784375           0.815625           0.800000   \n",
       "3            0.825000           0.796875           0.800000   \n",
       "19           0.768750           0.806250           0.812500   \n",
       "0            0.818750           0.778125           0.806250   \n",
       "17           0.759375           0.793750           0.809375   \n",
       "20           0.740625           0.775000           0.784375   \n",
       "22           0.628125           0.712500           0.725000   \n",
       "23           0.584375           0.696875           0.687500   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "5            0.843750         0.832500        0.012900                1  \n",
       "2            0.837500         0.830000        0.010753                2  \n",
       "8            0.843750         0.828750        0.010155                3  \n",
       "10           0.843750         0.824375        0.012717                4  \n",
       "4            0.834375         0.820625        0.011957                5  \n",
       "18           0.828125         0.820000        0.012748                6  \n",
       "7            0.834375         0.818125        0.013020                7  \n",
       "11           0.837500         0.816875        0.017071                8  \n",
       "13           0.828125         0.816250        0.010155                9  \n",
       "15           0.815625         0.815000        0.012087               10  \n",
       "1            0.818750         0.812500        0.008149               11  \n",
       "14           0.825000         0.812500        0.016298               11  \n",
       "12           0.812500         0.811250        0.011957               13  \n",
       "9            0.809375         0.808750        0.012870               14  \n",
       "6            0.809375         0.807500        0.015130               15  \n",
       "16           0.818750         0.806875        0.011250               16  \n",
       "21           0.812500         0.801875        0.011285               17  \n",
       "3            0.803125         0.801250        0.014059               18  \n",
       "19           0.815625         0.801250        0.016840               18  \n",
       "0            0.784375         0.793125        0.016465               20  \n",
       "17           0.803125         0.792500        0.017410               21  \n",
       "20           0.775000         0.771875        0.016178               22  \n",
       "22           0.700000         0.700625        0.038345               23  \n",
       "23           0.681250         0.670625        0.043777               24  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"outputs/MultinomialNB_polarity_grid_results.csv\")\n",
    "df.sort_values(by=\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24 entries, 0 to 23\n",
      "Data columns (total 15 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   mean_fit_time                  24 non-null     float64\n",
      " 1   std_fit_time                   24 non-null     float64\n",
      " 2   mean_score_time                24 non-null     float64\n",
      " 3   std_score_time                 24 non-null     float64\n",
      " 4   param_classifier__alpha        24 non-null     float64\n",
      " 5   param_vectorizer__ngram_range  24 non-null     object \n",
      " 6   params                         24 non-null     object \n",
      " 7   split0_test_score              24 non-null     float64\n",
      " 8   split1_test_score              24 non-null     float64\n",
      " 9   split2_test_score              24 non-null     float64\n",
      " 10  split3_test_score              24 non-null     float64\n",
      " 11  split4_test_score              24 non-null     float64\n",
      " 12  mean_test_score                24 non-null     float64\n",
      " 13  std_test_score                 24 non-null     float64\n",
      " 14  rank_test_score                24 non-null     int64  \n",
      "dtypes: float64(12), int64(1), object(2)\n",
      "memory usage: 2.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__alpha': 0.1, 'vectorizer__ngram_range': (1, 3)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "# best params\n",
    "best_params = literal_eval(df.sort_values(by=\"rank_test_score\").iloc[1][\"params\"])\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'memory': None, 'steps': [('vectorizer', CountVectorizer(dtype=<class 'numpy.float64'>, ngram_range=(1, 3))), ('classifier', MultinomialNB(alpha=0.1))], 'verbose': False, 'vectorizer': CountVectorizer(dtype=<class 'numpy.float64'>, ngram_range=(1, 3)), 'classifier': MultinomialNB(alpha=0.1), 'vectorizer__analyzer': 'word', 'vectorizer__binary': False, 'vectorizer__decode_error': 'strict', 'vectorizer__dtype': <class 'numpy.float64'>, 'vectorizer__encoding': 'utf-8', 'vectorizer__input': 'content', 'vectorizer__lowercase': True, 'vectorizer__max_df': 1.0, 'vectorizer__max_features': None, 'vectorizer__min_df': 1, 'vectorizer__ngram_range': (1, 3), 'vectorizer__preprocessor': None, 'vectorizer__stop_words': None, 'vectorizer__strip_accents': None, 'vectorizer__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'vectorizer__tokenizer': None, 'vectorizer__vocabulary': None, 'classifier__alpha': 0.1, 'classifier__class_prior': None, 'classifier__fit_prior': True, 'classifier__force_alpha': True}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "best_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"vectorizer\", CountVectorizer(dtype=np.float64)),\n",
    "        (\"classifier\", MultinomialNB())\n",
    "    ],\n",
    ")\n",
    "\n",
    "best_pipe = best_pipe.set_params(**best_params)\n",
    "print(best_pipe.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.85      0.80      0.82       200\n",
      "         pos       0.81      0.85      0.83       200\n",
      "\n",
      "    accuracy                           0.82       400\n",
      "   macro avg       0.83      0.82      0.82       400\n",
      "weighted avg       0.83      0.82      0.82       400\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "best_pipe.fit(X_train, y_train)\n",
    "preds = best_pipe.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds))\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_true=y_test,\n",
    "    y_pred=preds,\n",
    "    xticks_rotation=90\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__C</th>\n",
       "      <th>param_classifier__penalty</th>\n",
       "      <th>param_classifier__solver</th>\n",
       "      <th>param_classifier__tol</th>\n",
       "      <th>param_vectorizer__ngram_range</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>24.098338</td>\n",
       "      <td>1.349892</td>\n",
       "      <td>0.966499</td>\n",
       "      <td>0.341275</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__penalty': 'l...</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.846875</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.840625</td>\n",
       "      <td>0.809375</td>\n",
       "      <td>0.831875</td>\n",
       "      <td>0.017388</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2.357963</td>\n",
       "      <td>0.201027</td>\n",
       "      <td>0.283969</td>\n",
       "      <td>0.022385</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__penalty': 'l...</td>\n",
       "      <td>0.809375</td>\n",
       "      <td>0.821875</td>\n",
       "      <td>0.837500</td>\n",
       "      <td>0.868750</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.828750</td>\n",
       "      <td>0.022827</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>62.136795</td>\n",
       "      <td>4.138098</td>\n",
       "      <td>0.988155</td>\n",
       "      <td>0.481357</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__penalty': 'l...</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.840625</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.021469</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2.431994</td>\n",
       "      <td>0.053296</td>\n",
       "      <td>0.244074</td>\n",
       "      <td>0.013695</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__penalty': 'l...</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.815625</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.813750</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>16.205918</td>\n",
       "      <td>0.736606</td>\n",
       "      <td>0.692287</td>\n",
       "      <td>0.038642</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__penalty': 'l...</td>\n",
       "      <td>0.771875</td>\n",
       "      <td>0.837500</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.834375</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.813125</td>\n",
       "      <td>0.025109</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8.580147</td>\n",
       "      <td>0.149722</td>\n",
       "      <td>0.239662</td>\n",
       "      <td>0.017181</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__penalty': 'l...</td>\n",
       "      <td>0.771875</td>\n",
       "      <td>0.840625</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.803125</td>\n",
       "      <td>0.810625</td>\n",
       "      <td>0.022759</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>30.083034</td>\n",
       "      <td>0.515219</td>\n",
       "      <td>0.585488</td>\n",
       "      <td>0.079542</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__penalty': 'l...</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.837500</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.821875</td>\n",
       "      <td>0.790625</td>\n",
       "      <td>0.808125</td>\n",
       "      <td>0.027712</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>50.601026</td>\n",
       "      <td>1.326470</td>\n",
       "      <td>0.881842</td>\n",
       "      <td>0.058832</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__penalty': 'l...</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.790625</td>\n",
       "      <td>0.806875</td>\n",
       "      <td>0.026324</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>35.035143</td>\n",
       "      <td>0.824309</td>\n",
       "      <td>1.105001</td>\n",
       "      <td>0.119233</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__penalty': 'l...</td>\n",
       "      <td>0.768750</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.821875</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.805000</td>\n",
       "      <td>0.021524</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22.065703</td>\n",
       "      <td>1.823981</td>\n",
       "      <td>1.225890</td>\n",
       "      <td>0.255593</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>{'classifier__C': 0.0001, 'classifier__penalty...</td>\n",
       "      <td>0.709375</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.715625</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.717500</td>\n",
       "      <td>0.010193</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.546232</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.640589</td>\n",
       "      <td>0.060054</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__C': 0.0001, 'classifier__penalty...</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.715625</td>\n",
       "      <td>0.715625</td>\n",
       "      <td>0.728125</td>\n",
       "      <td>0.716875</td>\n",
       "      <td>0.005796</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.223153</td>\n",
       "      <td>0.090753</td>\n",
       "      <td>0.224678</td>\n",
       "      <td>0.028142</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'classifier__C': 0.0001, 'classifier__penalty...</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.709375</td>\n",
       "      <td>0.715625</td>\n",
       "      <td>0.709375</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.706875</td>\n",
       "      <td>0.006060</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.989881</td>\n",
       "      <td>0.717399</td>\n",
       "      <td>0.963843</td>\n",
       "      <td>0.051745</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>{'classifier__C': 0.0001, 'classifier__penalty...</td>\n",
       "      <td>0.659375</td>\n",
       "      <td>0.709375</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.696875</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.705625</td>\n",
       "      <td>0.026911</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.726015</td>\n",
       "      <td>0.196032</td>\n",
       "      <td>0.570041</td>\n",
       "      <td>0.015206</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__C': 0.0001, 'classifier__penalty...</td>\n",
       "      <td>0.659375</td>\n",
       "      <td>0.709375</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.693750</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.703750</td>\n",
       "      <td>0.025724</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.478251</td>\n",
       "      <td>0.063468</td>\n",
       "      <td>0.236906</td>\n",
       "      <td>0.026432</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'classifier__C': 0.0001, 'classifier__penalty...</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.709375</td>\n",
       "      <td>0.715625</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.728125</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.029288</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5.154773</td>\n",
       "      <td>0.392965</td>\n",
       "      <td>0.573368</td>\n",
       "      <td>0.053250</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__penalty': 'l...</td>\n",
       "      <td>0.606250</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.690625</td>\n",
       "      <td>0.678125</td>\n",
       "      <td>0.040601</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.720665</td>\n",
       "      <td>0.106384</td>\n",
       "      <td>0.583759</td>\n",
       "      <td>0.056371</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__C': 0.0001, 'classifier__penalty...</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>0.706250</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.668750</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.675625</td>\n",
       "      <td>0.036997</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.239577</td>\n",
       "      <td>0.051575</td>\n",
       "      <td>0.261235</td>\n",
       "      <td>0.014031</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__penalty': 'l...</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.715625</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.684375</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.665000</td>\n",
       "      <td>0.031586</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.318956</td>\n",
       "      <td>0.107658</td>\n",
       "      <td>0.280420</td>\n",
       "      <td>0.054120</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__penalty': 'l...</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.665625</td>\n",
       "      <td>0.696875</td>\n",
       "      <td>0.655625</td>\n",
       "      <td>0.046912</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>12.073860</td>\n",
       "      <td>0.604953</td>\n",
       "      <td>1.123064</td>\n",
       "      <td>0.085109</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__penalty': 'l...</td>\n",
       "      <td>0.615625</td>\n",
       "      <td>0.581250</td>\n",
       "      <td>0.706250</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.715625</td>\n",
       "      <td>0.643750</td>\n",
       "      <td>0.056006</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.913350</td>\n",
       "      <td>0.360057</td>\n",
       "      <td>1.082762</td>\n",
       "      <td>0.229836</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>{'classifier__C': 0.0001, 'classifier__penalty...</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.584375</td>\n",
       "      <td>0.693750</td>\n",
       "      <td>0.653125</td>\n",
       "      <td>0.565625</td>\n",
       "      <td>0.631875</td>\n",
       "      <td>0.048710</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11.659568</td>\n",
       "      <td>0.252765</td>\n",
       "      <td>0.903053</td>\n",
       "      <td>0.054045</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__penalty': 'l...</td>\n",
       "      <td>0.596875</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.643750</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.584375</td>\n",
       "      <td>0.627500</td>\n",
       "      <td>0.032259</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.161923</td>\n",
       "      <td>0.179919</td>\n",
       "      <td>0.522854</td>\n",
       "      <td>0.055447</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__penalty': 'l...</td>\n",
       "      <td>0.618750</td>\n",
       "      <td>0.590625</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.659375</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.033923</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.050541</td>\n",
       "      <td>0.058818</td>\n",
       "      <td>0.228735</td>\n",
       "      <td>0.013156</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'classifier__C': 0.0001, 'classifier__penalty...</td>\n",
       "      <td>0.590625</td>\n",
       "      <td>0.556250</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.070561</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.179714</td>\n",
       "      <td>0.016213</td>\n",
       "      <td>0.262031</td>\n",
       "      <td>0.020163</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'classifier__C': 0.0001, 'classifier__penalty...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.851713</td>\n",
       "      <td>0.190985</td>\n",
       "      <td>0.873280</td>\n",
       "      <td>0.070315</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>{'classifier__C': 0.0001, 'classifier__penalty...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.073367</td>\n",
       "      <td>0.230178</td>\n",
       "      <td>0.596382</td>\n",
       "      <td>0.017991</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__C': 0.0001, 'classifier__penalty...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.219017</td>\n",
       "      <td>0.068244</td>\n",
       "      <td>0.264283</td>\n",
       "      <td>0.008556</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'classifier__C': 0.0001, 'classifier__penalty...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>11.111121</td>\n",
       "      <td>2.706994</td>\n",
       "      <td>0.824757</td>\n",
       "      <td>0.074371</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>{'classifier__C': 0.0001, 'classifier__penalty...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6.457254</td>\n",
       "      <td>2.769098</td>\n",
       "      <td>0.751169</td>\n",
       "      <td>0.274943</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__C': 0.0001, 'classifier__penalty...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.436148</td>\n",
       "      <td>0.093114</td>\n",
       "      <td>0.877840</td>\n",
       "      <td>0.047086</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>{'classifier__C': 0.0001, 'classifier__penalty...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.872304</td>\n",
       "      <td>0.024975</td>\n",
       "      <td>0.214527</td>\n",
       "      <td>0.018079</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'classifier__C': 0.0001, 'classifier__penalty...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>8.918014</td>\n",
       "      <td>1.073521</td>\n",
       "      <td>0.944689</td>\n",
       "      <td>0.162473</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__penalty': 'l...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.412068</td>\n",
       "      <td>0.211534</td>\n",
       "      <td>0.284991</td>\n",
       "      <td>0.040649</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__penalty': 'l...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>20.420680</td>\n",
       "      <td>5.265476</td>\n",
       "      <td>1.098196</td>\n",
       "      <td>0.340498</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__penalty': 'l...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.219851</td>\n",
       "      <td>0.178561</td>\n",
       "      <td>0.533256</td>\n",
       "      <td>0.062338</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__C': 0.0001, 'classifier__penalty...</td>\n",
       "      <td>0.496875</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.499375</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9.240936</td>\n",
       "      <td>0.125994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>{'classifier__C': 0.0001, 'classifier__penalty...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.917389</td>\n",
       "      <td>0.096862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__C': 0.0001, 'classifier__penalty...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.059556</td>\n",
       "      <td>0.007731</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'classifier__C': 0.0001, 'classifier__penalty...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.122224</td>\n",
       "      <td>0.129884</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>{'classifier__C': 0.0001, 'classifier__penalty...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4.030319</td>\n",
       "      <td>0.123985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__penalty': 'l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.090614</td>\n",
       "      <td>0.066644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__penalty': 'l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.001156</td>\n",
       "      <td>0.140287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__C': 0.0001, 'classifier__penalty...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.099927</td>\n",
       "      <td>0.046080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'classifier__C': 0.0001, 'classifier__penalty...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>9.321761</td>\n",
       "      <td>0.158676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__penalty': 'l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.999118</td>\n",
       "      <td>0.080328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__penalty': 'l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4.065541</td>\n",
       "      <td>0.113173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__penalty': 'l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>9.597728</td>\n",
       "      <td>0.123044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__penalty': 'l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "43      24.098338      1.349892         0.966499        0.341275   \n",
       "42       2.357963      0.201027         0.283969        0.022385   \n",
       "44      62.136795      4.138098         0.988155        0.481357   \n",
       "36       2.431994      0.053296         0.244074        0.013695   \n",
       "37      16.205918      0.736606         0.692287        0.038642   \n",
       "24       8.580147      0.149722         0.239662        0.017181   \n",
       "25      30.083034      0.515219         0.585488        0.079542   \n",
       "26      50.601026      1.326470         0.881842        0.058832   \n",
       "38      35.035143      0.824309         1.105001        0.119233   \n",
       "20      22.065703      1.823981         1.225890        0.255593   \n",
       "19       6.546232      0.162791         0.640589        0.060054   \n",
       "18       1.223153      0.090753         0.224678        0.028142   \n",
       "14      15.989881      0.717399         0.963843        0.051745   \n",
       "13       6.726015      0.196032         0.570041        0.015206   \n",
       "12       1.478251      0.063468         0.236906        0.026432   \n",
       "40       5.154773      0.392965         0.573368        0.053250   \n",
       "16       4.720665      0.106384         0.583759        0.056371   \n",
       "39       1.239577      0.051575         0.261235        0.014031   \n",
       "27       1.318956      0.107658         0.280420        0.054120   \n",
       "41      12.073860      0.604953         1.123064        0.085109   \n",
       "17       9.913350      0.360057         1.082762        0.229836   \n",
       "29      11.659568      0.252765         0.903053        0.054045   \n",
       "28       5.161923      0.179919         0.522854        0.055447   \n",
       "15       1.050541      0.058818         0.228735        0.013156   \n",
       "3        1.179714      0.016213         0.262031        0.020163   \n",
       "2        9.851713      0.190985         0.873280        0.070315   \n",
       "1        4.073367      0.230178         0.596382        0.017991   \n",
       "21       1.219017      0.068244         0.264283        0.008556   \n",
       "23      11.111121      2.706994         0.824757        0.074371   \n",
       "22       6.457254      2.769098         0.751169        0.274943   \n",
       "5        9.436148      0.093114         0.877840        0.047086   \n",
       "0        0.872304      0.024975         0.214527        0.018079   \n",
       "46       8.918014      1.073521         0.944689        0.162473   \n",
       "45       1.412068      0.211534         0.284991        0.040649   \n",
       "47      20.420680      5.265476         1.098196        0.340498   \n",
       "4        4.219851      0.178561         0.533256        0.062338   \n",
       "11       9.240936      0.125994         0.000000        0.000000   \n",
       "10       3.917389      0.096862         0.000000        0.000000   \n",
       "9        1.059556      0.007731         0.000000        0.000000   \n",
       "8        9.122224      0.129884         0.000000        0.000000   \n",
       "31       4.030319      0.123985         0.000000        0.000000   \n",
       "30       1.090614      0.066644         0.000000        0.000000   \n",
       "7        4.001156      0.140287         0.000000        0.000000   \n",
       "6        1.099927      0.046080         0.000000        0.000000   \n",
       "32       9.321761      0.158676         0.000000        0.000000   \n",
       "33       0.999118      0.080328         0.000000        0.000000   \n",
       "34       4.065541      0.113173         0.000000        0.000000   \n",
       "35       9.597728      0.123044         0.000000        0.000000   \n",
       "\n",
       "    param_classifier__C param_classifier__penalty param_classifier__solver  \\\n",
       "43               1.0000                        l2                    lbfgs   \n",
       "42               1.0000                        l2                    lbfgs   \n",
       "44               1.0000                        l2                    lbfgs   \n",
       "36               1.0000                        l2                     saga   \n",
       "37               1.0000                        l2                     saga   \n",
       "24               1.0000                        l1                     saga   \n",
       "25               1.0000                        l1                     saga   \n",
       "26               1.0000                        l1                     saga   \n",
       "38               1.0000                        l2                     saga   \n",
       "20               0.0001                        l2                    lbfgs   \n",
       "19               0.0001                        l2                    lbfgs   \n",
       "18               0.0001                        l2                    lbfgs   \n",
       "14               0.0001                        l2                     saga   \n",
       "13               0.0001                        l2                     saga   \n",
       "12               0.0001                        l2                     saga   \n",
       "40               1.0000                        l2                     saga   \n",
       "16               0.0001                        l2                     saga   \n",
       "39               1.0000                        l2                     saga   \n",
       "27               1.0000                        l1                     saga   \n",
       "41               1.0000                        l2                     saga   \n",
       "17               0.0001                        l2                     saga   \n",
       "29               1.0000                        l1                     saga   \n",
       "28               1.0000                        l1                     saga   \n",
       "15               0.0001                        l2                     saga   \n",
       "3                0.0001                        l1                     saga   \n",
       "2                0.0001                        l1                     saga   \n",
       "1                0.0001                        l1                     saga   \n",
       "21               0.0001                        l2                    lbfgs   \n",
       "23               0.0001                        l2                    lbfgs   \n",
       "22               0.0001                        l2                    lbfgs   \n",
       "5                0.0001                        l1                     saga   \n",
       "0                0.0001                        l1                     saga   \n",
       "46               1.0000                        l2                    lbfgs   \n",
       "45               1.0000                        l2                    lbfgs   \n",
       "47               1.0000                        l2                    lbfgs   \n",
       "4                0.0001                        l1                     saga   \n",
       "11               0.0001                        l1                    lbfgs   \n",
       "10               0.0001                        l1                    lbfgs   \n",
       "9                0.0001                        l1                    lbfgs   \n",
       "8                0.0001                        l1                    lbfgs   \n",
       "31               1.0000                        l1                    lbfgs   \n",
       "30               1.0000                        l1                    lbfgs   \n",
       "7                0.0001                        l1                    lbfgs   \n",
       "6                0.0001                        l1                    lbfgs   \n",
       "32               1.0000                        l1                    lbfgs   \n",
       "33               1.0000                        l1                    lbfgs   \n",
       "34               1.0000                        l1                    lbfgs   \n",
       "35               1.0000                        l1                    lbfgs   \n",
       "\n",
       "    param_classifier__tol param_vectorizer__ngram_range  \\\n",
       "43                 0.0001                        (1, 2)   \n",
       "42                 0.0001                        (1, 1)   \n",
       "44                 0.0001                        (1, 3)   \n",
       "36                 0.0001                        (1, 1)   \n",
       "37                 0.0001                        (1, 2)   \n",
       "24                 0.0001                        (1, 1)   \n",
       "25                 0.0001                        (1, 2)   \n",
       "26                 0.0001                        (1, 3)   \n",
       "38                 0.0001                        (1, 3)   \n",
       "20                 0.0001                        (1, 3)   \n",
       "19                 0.0001                        (1, 2)   \n",
       "18                 0.0001                        (1, 1)   \n",
       "14                 0.0001                        (1, 3)   \n",
       "13                 0.0001                        (1, 2)   \n",
       "12                 0.0001                        (1, 1)   \n",
       "40                 1.0000                        (1, 2)   \n",
       "16                 1.0000                        (1, 2)   \n",
       "39                 1.0000                        (1, 1)   \n",
       "27                 1.0000                        (1, 1)   \n",
       "41                 1.0000                        (1, 3)   \n",
       "17                 1.0000                        (1, 3)   \n",
       "29                 1.0000                        (1, 3)   \n",
       "28                 1.0000                        (1, 2)   \n",
       "15                 1.0000                        (1, 1)   \n",
       "3                  1.0000                        (1, 1)   \n",
       "2                  0.0001                        (1, 3)   \n",
       "1                  0.0001                        (1, 2)   \n",
       "21                 1.0000                        (1, 1)   \n",
       "23                 1.0000                        (1, 3)   \n",
       "22                 1.0000                        (1, 2)   \n",
       "5                  1.0000                        (1, 3)   \n",
       "0                  0.0001                        (1, 1)   \n",
       "46                 1.0000                        (1, 2)   \n",
       "45                 1.0000                        (1, 1)   \n",
       "47                 1.0000                        (1, 3)   \n",
       "4                  1.0000                        (1, 2)   \n",
       "11                 1.0000                        (1, 3)   \n",
       "10                 1.0000                        (1, 2)   \n",
       "9                  1.0000                        (1, 1)   \n",
       "8                  0.0001                        (1, 3)   \n",
       "31                 0.0001                        (1, 2)   \n",
       "30                 0.0001                        (1, 1)   \n",
       "7                  0.0001                        (1, 2)   \n",
       "6                  0.0001                        (1, 1)   \n",
       "32                 0.0001                        (1, 3)   \n",
       "33                 1.0000                        (1, 1)   \n",
       "34                 1.0000                        (1, 2)   \n",
       "35                 1.0000                        (1, 3)   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "43  {'classifier__C': 1, 'classifier__penalty': 'l...           0.812500   \n",
       "42  {'classifier__C': 1, 'classifier__penalty': 'l...           0.809375   \n",
       "44  {'classifier__C': 1, 'classifier__penalty': 'l...           0.793750   \n",
       "36  {'classifier__C': 1, 'classifier__penalty': 'l...           0.775000   \n",
       "37  {'classifier__C': 1, 'classifier__penalty': 'l...           0.771875   \n",
       "24  {'classifier__C': 1, 'classifier__penalty': 'l...           0.771875   \n",
       "25  {'classifier__C': 1, 'classifier__penalty': 'l...           0.762500   \n",
       "26  {'classifier__C': 1, 'classifier__penalty': 'l...           0.762500   \n",
       "38  {'classifier__C': 1, 'classifier__penalty': 'l...           0.768750   \n",
       "20  {'classifier__C': 0.0001, 'classifier__penalty...           0.709375   \n",
       "19  {'classifier__C': 0.0001, 'classifier__penalty...           0.712500   \n",
       "18  {'classifier__C': 0.0001, 'classifier__penalty...           0.700000   \n",
       "14  {'classifier__C': 0.0001, 'classifier__penalty...           0.659375   \n",
       "13  {'classifier__C': 0.0001, 'classifier__penalty...           0.659375   \n",
       "12  {'classifier__C': 0.0001, 'classifier__penalty...           0.650000   \n",
       "40  {'classifier__C': 1, 'classifier__penalty': 'l...           0.606250   \n",
       "16  {'classifier__C': 0.0001, 'classifier__penalty...           0.612500   \n",
       "39  {'classifier__C': 1, 'classifier__penalty': 'l...           0.625000   \n",
       "27  {'classifier__C': 1, 'classifier__penalty': 'l...           0.609375   \n",
       "41  {'classifier__C': 1, 'classifier__penalty': 'l...           0.615625   \n",
       "17  {'classifier__C': 0.0001, 'classifier__penalty...           0.662500   \n",
       "29  {'classifier__C': 1, 'classifier__penalty': 'l...           0.596875   \n",
       "28  {'classifier__C': 1, 'classifier__penalty': 'l...           0.618750   \n",
       "15  {'classifier__C': 0.0001, 'classifier__penalty...           0.590625   \n",
       "3   {'classifier__C': 0.0001, 'classifier__penalty...           0.500000   \n",
       "2   {'classifier__C': 0.0001, 'classifier__penalty...           0.500000   \n",
       "1   {'classifier__C': 0.0001, 'classifier__penalty...           0.500000   \n",
       "21  {'classifier__C': 0.0001, 'classifier__penalty...           0.500000   \n",
       "23  {'classifier__C': 0.0001, 'classifier__penalty...           0.500000   \n",
       "22  {'classifier__C': 0.0001, 'classifier__penalty...           0.500000   \n",
       "5   {'classifier__C': 0.0001, 'classifier__penalty...           0.500000   \n",
       "0   {'classifier__C': 0.0001, 'classifier__penalty...           0.500000   \n",
       "46  {'classifier__C': 1, 'classifier__penalty': 'l...           0.500000   \n",
       "45  {'classifier__C': 1, 'classifier__penalty': 'l...           0.500000   \n",
       "47  {'classifier__C': 1, 'classifier__penalty': 'l...           0.500000   \n",
       "4   {'classifier__C': 0.0001, 'classifier__penalty...           0.496875   \n",
       "11  {'classifier__C': 0.0001, 'classifier__penalty...                NaN   \n",
       "10  {'classifier__C': 0.0001, 'classifier__penalty...                NaN   \n",
       "9   {'classifier__C': 0.0001, 'classifier__penalty...                NaN   \n",
       "8   {'classifier__C': 0.0001, 'classifier__penalty...                NaN   \n",
       "31  {'classifier__C': 1, 'classifier__penalty': 'l...                NaN   \n",
       "30  {'classifier__C': 1, 'classifier__penalty': 'l...                NaN   \n",
       "7   {'classifier__C': 0.0001, 'classifier__penalty...                NaN   \n",
       "6   {'classifier__C': 0.0001, 'classifier__penalty...                NaN   \n",
       "32  {'classifier__C': 1, 'classifier__penalty': 'l...                NaN   \n",
       "33  {'classifier__C': 1, 'classifier__penalty': 'l...                NaN   \n",
       "34  {'classifier__C': 1, 'classifier__penalty': 'l...                NaN   \n",
       "35  {'classifier__C': 1, 'classifier__penalty': 'l...                NaN   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "43           0.846875           0.850000           0.840625   \n",
       "42           0.821875           0.837500           0.868750   \n",
       "44           0.843750           0.850000           0.840625   \n",
       "36           0.843750           0.815625           0.828125   \n",
       "37           0.837500           0.825000           0.834375   \n",
       "24           0.840625           0.818750           0.818750   \n",
       "25           0.837500           0.828125           0.821875   \n",
       "26           0.828125           0.828125           0.825000   \n",
       "38           0.828125           0.821875           0.812500   \n",
       "20           0.712500           0.715625           0.712500   \n",
       "19           0.712500           0.715625           0.715625   \n",
       "18           0.709375           0.715625           0.709375   \n",
       "14           0.709375           0.737500           0.696875   \n",
       "13           0.709375           0.731250           0.693750   \n",
       "12           0.709375           0.715625           0.671875   \n",
       "40           0.687500           0.731250           0.675000   \n",
       "16           0.706250           0.718750           0.668750   \n",
       "39           0.715625           0.650000           0.684375   \n",
       "27           0.712500           0.593750           0.665625   \n",
       "41           0.581250           0.706250           0.600000   \n",
       "17           0.584375           0.693750           0.653125   \n",
       "29           0.671875           0.643750           0.640625   \n",
       "28           0.590625           0.575000           0.659375   \n",
       "15           0.556250           0.731250           0.671875   \n",
       "3            0.500000           0.500000           0.500000   \n",
       "2            0.500000           0.500000           0.500000   \n",
       "1            0.500000           0.500000           0.500000   \n",
       "21           0.500000           0.500000           0.500000   \n",
       "23           0.500000           0.500000           0.500000   \n",
       "22           0.500000           0.500000           0.500000   \n",
       "5            0.500000           0.500000           0.500000   \n",
       "0            0.500000           0.500000           0.500000   \n",
       "46           0.500000           0.500000           0.500000   \n",
       "45           0.500000           0.500000           0.500000   \n",
       "47           0.500000           0.500000           0.500000   \n",
       "4            0.500000           0.500000           0.500000   \n",
       "11                NaN                NaN                NaN   \n",
       "10                NaN                NaN                NaN   \n",
       "9                 NaN                NaN                NaN   \n",
       "8                 NaN                NaN                NaN   \n",
       "31                NaN                NaN                NaN   \n",
       "30                NaN                NaN                NaN   \n",
       "7                 NaN                NaN                NaN   \n",
       "6                 NaN                NaN                NaN   \n",
       "32                NaN                NaN                NaN   \n",
       "33                NaN                NaN                NaN   \n",
       "34                NaN                NaN                NaN   \n",
       "35                NaN                NaN                NaN   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "43           0.809375         0.831875        0.017388                1  \n",
       "42           0.806250         0.828750        0.022827                2  \n",
       "44           0.812500         0.828125        0.021469                3  \n",
       "36           0.806250         0.813750        0.023100                4  \n",
       "37           0.796875         0.813125        0.025109                5  \n",
       "24           0.803125         0.810625        0.022759                6  \n",
       "25           0.790625         0.808125        0.027712                7  \n",
       "26           0.790625         0.806875        0.026324                8  \n",
       "38           0.793750         0.805000        0.021524                9  \n",
       "20           0.737500         0.717500        0.010193               10  \n",
       "19           0.728125         0.716875        0.005796               11  \n",
       "18           0.700000         0.706875        0.006060               12  \n",
       "14           0.725000         0.705625        0.026911               13  \n",
       "13           0.725000         0.703750        0.025724               14  \n",
       "12           0.728125         0.695000        0.029288               15  \n",
       "40           0.690625         0.678125        0.040601               16  \n",
       "16           0.671875         0.675625        0.036997               17  \n",
       "39           0.650000         0.665000        0.031586               18  \n",
       "27           0.696875         0.655625        0.046912               19  \n",
       "41           0.715625         0.643750        0.056006               20  \n",
       "17           0.565625         0.631875        0.048710               21  \n",
       "29           0.584375         0.627500        0.032259               22  \n",
       "28           0.656250         0.620000        0.033923               23  \n",
       "15           0.550000         0.620000        0.070561               24  \n",
       "3            0.500000         0.500000        0.000000               25  \n",
       "2            0.500000         0.500000        0.000000               25  \n",
       "1            0.500000         0.500000        0.000000               25  \n",
       "21           0.500000         0.500000        0.000000               25  \n",
       "23           0.500000         0.500000        0.000000               25  \n",
       "22           0.500000         0.500000        0.000000               25  \n",
       "5            0.500000         0.500000        0.000000               25  \n",
       "0            0.500000         0.500000        0.000000               25  \n",
       "46           0.500000         0.500000        0.000000               25  \n",
       "45           0.500000         0.500000        0.000000               25  \n",
       "47           0.500000         0.500000        0.000000               25  \n",
       "4            0.500000         0.499375        0.001250               36  \n",
       "11                NaN              NaN             NaN               37  \n",
       "10                NaN              NaN             NaN               37  \n",
       "9                 NaN              NaN             NaN               37  \n",
       "8                 NaN              NaN             NaN               37  \n",
       "31                NaN              NaN             NaN               37  \n",
       "30                NaN              NaN             NaN               37  \n",
       "7                 NaN              NaN             NaN               37  \n",
       "6                 NaN              NaN             NaN               37  \n",
       "32                NaN              NaN             NaN               37  \n",
       "33                NaN              NaN             NaN               37  \n",
       "34                NaN              NaN             NaN               37  \n",
       "35                NaN              NaN             NaN               37  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"outputs/LogisticRegression_polarity_grid_results.csv\")\n",
    "df.sort_values(by=\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 1,\n",
       " 'classifier__penalty': 'l2',\n",
       " 'classifier__solver': 'lbfgs',\n",
       " 'classifier__tol': 0.0001,\n",
       " 'vectorizer__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "# best params\n",
    "best_params = literal_eval(df.sort_values(by=\"rank_test_score\").iloc[1][\"params\"])\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'memory': None, 'steps': [('vectorizer', CountVectorizer(dtype=<class 'numpy.float64'>)), ('classifier', LogisticRegression(C=1))], 'verbose': False, 'vectorizer': CountVectorizer(dtype=<class 'numpy.float64'>), 'classifier': LogisticRegression(C=1), 'vectorizer__analyzer': 'word', 'vectorizer__binary': False, 'vectorizer__decode_error': 'strict', 'vectorizer__dtype': <class 'numpy.float64'>, 'vectorizer__encoding': 'utf-8', 'vectorizer__input': 'content', 'vectorizer__lowercase': True, 'vectorizer__max_df': 1.0, 'vectorizer__max_features': None, 'vectorizer__min_df': 1, 'vectorizer__ngram_range': (1, 1), 'vectorizer__preprocessor': None, 'vectorizer__stop_words': None, 'vectorizer__strip_accents': None, 'vectorizer__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'vectorizer__tokenizer': None, 'vectorizer__vocabulary': None, 'classifier__C': 1, 'classifier__class_weight': None, 'classifier__dual': False, 'classifier__fit_intercept': True, 'classifier__intercept_scaling': 1, 'classifier__l1_ratio': None, 'classifier__max_iter': 100, 'classifier__multi_class': 'deprecated', 'classifier__n_jobs': None, 'classifier__penalty': 'l2', 'classifier__random_state': None, 'classifier__solver': 'lbfgs', 'classifier__tol': 0.0001, 'classifier__verbose': 0, 'classifier__warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "best_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"vectorizer\", CountVectorizer(dtype=np.float64)),\n",
    "        (\"classifier\", LogisticRegression())\n",
    "    ],\n",
    ")\n",
    "\n",
    "best_pipe = best_pipe.set_params(**best_params)\n",
    "print(best_pipe.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/unb/unb_mestrado/2_semestre/topicos_nlp/nlp/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.82      0.88      0.85       200\n",
      "         pos       0.87      0.81      0.83       200\n",
      "\n",
      "    accuracy                           0.84       400\n",
      "   macro avg       0.84      0.84      0.84       400\n",
      "weighted avg       0.84      0.84      0.84       400\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_pipe.fit(X_train, y_train)\n",
    "preds = best_pipe.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds))\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_true=y_test,\n",
    "    y_pred=preds,\n",
    "    xticks_rotation=90\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__boosting_type</th>\n",
       "      <th>param_classifier__learning_rate</th>\n",
       "      <th>param_classifier__num_leaves</th>\n",
       "      <th>param_vectorizer__ngram_range</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>57.283318</td>\n",
       "      <td>7.980517</td>\n",
       "      <td>0.844147</td>\n",
       "      <td>0.142138</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__boosting_type': 'gbdt', 'classif...</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.853125</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.835625</td>\n",
       "      <td>0.023435</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>54.378674</td>\n",
       "      <td>30.504263</td>\n",
       "      <td>0.359543</td>\n",
       "      <td>0.092158</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'classifier__boosting_type': 'gbdt', 'classif...</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.846875</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.837500</td>\n",
       "      <td>0.829375</td>\n",
       "      <td>0.022673</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>116.754446</td>\n",
       "      <td>26.266212</td>\n",
       "      <td>0.939559</td>\n",
       "      <td>0.122278</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__boosting_type': 'gbdt', 'classif...</td>\n",
       "      <td>0.809375</td>\n",
       "      <td>0.846875</td>\n",
       "      <td>0.834375</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.826875</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>159.735271</td>\n",
       "      <td>19.288703</td>\n",
       "      <td>1.636696</td>\n",
       "      <td>0.172737</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>{'classifier__boosting_type': 'gbdt', 'classif...</td>\n",
       "      <td>0.778125</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.834375</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.853125</td>\n",
       "      <td>0.825625</td>\n",
       "      <td>0.027769</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>234.700427</td>\n",
       "      <td>18.724303</td>\n",
       "      <td>1.630637</td>\n",
       "      <td>0.192624</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.1</td>\n",
       "      <td>31</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>{'classifier__boosting_type': 'gbdt', 'classif...</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.840625</td>\n",
       "      <td>0.821875</td>\n",
       "      <td>0.840625</td>\n",
       "      <td>0.823750</td>\n",
       "      <td>0.019526</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.916863</td>\n",
       "      <td>0.308458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>40</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__boosting_type': 'rf', 'classifie...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>19.089769</td>\n",
       "      <td>0.194915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>40</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>{'classifier__boosting_type': 'rf', 'classifie...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1.519425</td>\n",
       "      <td>0.111671</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'classifier__boosting_type': 'rf', 'classifie...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>8.172029</td>\n",
       "      <td>0.521319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'classifier__boosting_type': 'rf', 'classifie...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>14.350167</td>\n",
       "      <td>1.064621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>{'classifier__boosting_type': 'rf', 'classifie...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "31       57.283318      7.980517         0.844147        0.142138   \n",
       "30       54.378674     30.504263         0.359543        0.092158   \n",
       "34      116.754446     26.266212         0.939559        0.122278   \n",
       "35      159.735271     19.288703         1.636696        0.172737   \n",
       "38      234.700427     18.724303         1.630637        0.192624   \n",
       "..             ...           ...              ...             ...   \n",
       "130       7.916863      0.308458         0.000000        0.000000   \n",
       "131      19.089769      0.194915         0.000000        0.000000   \n",
       "132       1.519425      0.111671         0.000000        0.000000   \n",
       "133       8.172029      0.521319         0.000000        0.000000   \n",
       "134      14.350167      1.064621         0.000000        0.000000   \n",
       "\n",
       "    param_classifier__boosting_type  param_classifier__learning_rate  \\\n",
       "31                             gbdt                              0.1   \n",
       "30                             gbdt                              0.1   \n",
       "34                             gbdt                              0.1   \n",
       "35                             gbdt                              0.1   \n",
       "38                             gbdt                              0.1   \n",
       "..                              ...                              ...   \n",
       "130                              rf                              0.1   \n",
       "131                              rf                              0.1   \n",
       "132                              rf                              0.1   \n",
       "133                              rf                              0.1   \n",
       "134                              rf                              0.1   \n",
       "\n",
       "     param_classifier__num_leaves param_vectorizer__ngram_range  \\\n",
       "31                             10                        (1, 2)   \n",
       "30                             10                        (1, 1)   \n",
       "34                             20                        (1, 2)   \n",
       "35                             20                        (1, 3)   \n",
       "38                             31                        (1, 3)   \n",
       "..                            ...                           ...   \n",
       "130                            40                        (1, 2)   \n",
       "131                            40                        (1, 3)   \n",
       "132                            50                        (1, 1)   \n",
       "133                            50                        (1, 2)   \n",
       "134                            50                        (1, 3)   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "31   {'classifier__boosting_type': 'gbdt', 'classif...           0.793750   \n",
       "30   {'classifier__boosting_type': 'gbdt', 'classif...           0.787500   \n",
       "34   {'classifier__boosting_type': 'gbdt', 'classif...           0.809375   \n",
       "35   {'classifier__boosting_type': 'gbdt', 'classif...           0.778125   \n",
       "38   {'classifier__boosting_type': 'gbdt', 'classif...           0.787500   \n",
       "..                                                 ...                ...   \n",
       "130  {'classifier__boosting_type': 'rf', 'classifie...                NaN   \n",
       "131  {'classifier__boosting_type': 'rf', 'classifie...                NaN   \n",
       "132  {'classifier__boosting_type': 'rf', 'classifie...                NaN   \n",
       "133  {'classifier__boosting_type': 'rf', 'classifie...                NaN   \n",
       "134  {'classifier__boosting_type': 'rf', 'classifie...                NaN   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "31            0.859375           0.853125           0.828125   \n",
       "30            0.850000           0.846875           0.825000   \n",
       "34            0.846875           0.834375           0.818750   \n",
       "35            0.850000           0.834375           0.812500   \n",
       "38            0.828125           0.840625           0.821875   \n",
       "..                 ...                ...                ...   \n",
       "130                NaN                NaN                NaN   \n",
       "131                NaN                NaN                NaN   \n",
       "132                NaN                NaN                NaN   \n",
       "133                NaN                NaN                NaN   \n",
       "134                NaN                NaN                NaN   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "31            0.843750         0.835625        0.023435                1  \n",
       "30            0.837500         0.829375        0.022673                2  \n",
       "34            0.825000         0.826875        0.012900                3  \n",
       "35            0.853125         0.825625        0.027769                4  \n",
       "38            0.840625         0.823750        0.019526                5  \n",
       "..                 ...              ...             ...              ...  \n",
       "130                NaN              NaN             NaN               91  \n",
       "131                NaN              NaN             NaN               91  \n",
       "132                NaN              NaN             NaN               91  \n",
       "133                NaN              NaN             NaN               91  \n",
       "134                NaN              NaN             NaN               91  \n",
       "\n",
       "[135 rows x 17 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"outputs/LGBMClassifier_polarity_grid_results.csv\")\n",
    "df.sort_values(by=\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__boosting_type': 'gbdt',\n",
       " 'classifier__learning_rate': 0.1,\n",
       " 'classifier__num_leaves': 10,\n",
       " 'vectorizer__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "# best params\n",
    "best_params = literal_eval(df.sort_values(by=\"rank_test_score\").iloc[1][\"params\"])\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'memory': None, 'steps': [('vectorizer', CountVectorizer(dtype=<class 'numpy.float64'>)), ('classifier', LGBMClassifier(num_leaves=10, objective='binary', verbose=-1))], 'verbose': False, 'vectorizer': CountVectorizer(dtype=<class 'numpy.float64'>), 'classifier': LGBMClassifier(num_leaves=10, objective='binary', verbose=-1), 'vectorizer__analyzer': 'word', 'vectorizer__binary': False, 'vectorizer__decode_error': 'strict', 'vectorizer__dtype': <class 'numpy.float64'>, 'vectorizer__encoding': 'utf-8', 'vectorizer__input': 'content', 'vectorizer__lowercase': True, 'vectorizer__max_df': 1.0, 'vectorizer__max_features': None, 'vectorizer__min_df': 1, 'vectorizer__ngram_range': (1, 1), 'vectorizer__preprocessor': None, 'vectorizer__stop_words': None, 'vectorizer__strip_accents': None, 'vectorizer__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'vectorizer__tokenizer': None, 'vectorizer__vocabulary': None, 'classifier__boosting_type': 'gbdt', 'classifier__class_weight': None, 'classifier__colsample_bytree': 1.0, 'classifier__importance_type': 'split', 'classifier__learning_rate': 0.1, 'classifier__max_depth': -1, 'classifier__min_child_samples': 20, 'classifier__min_child_weight': 0.001, 'classifier__min_split_gain': 0.0, 'classifier__n_estimators': 100, 'classifier__n_jobs': None, 'classifier__num_leaves': 10, 'classifier__objective': 'binary', 'classifier__random_state': None, 'classifier__reg_alpha': 0.0, 'classifier__reg_lambda': 0.0, 'classifier__subsample': 1.0, 'classifier__subsample_for_bin': 200000, 'classifier__subsample_freq': 0, 'classifier__verbose': -1}\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "best_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"vectorizer\", CountVectorizer(dtype=np.float64)),\n",
    "        (\"classifier\", LGBMClassifier(objective=\"binary\", verbose=-1))\n",
    "    ],\n",
    ")\n",
    "\n",
    "best_pipe = best_pipe.set_params(**best_params)\n",
    "print(best_pipe.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.85      0.81      0.83       200\n",
      "         pos       0.82      0.85      0.84       200\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.83      0.83      0.83       400\n",
      "weighted avg       0.83      0.83      0.83       400\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_pipe.fit(X_train, y_train)\n",
    "preds = best_pipe.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds))\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_true=y_test,\n",
    "    y_pred=preds,\n",
    "    xticks_rotation=90\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
